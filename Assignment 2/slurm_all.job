#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=HyperparamSweep
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=18:00:00  # Increased time limit for more runs
#SBATCH --output=slurm_output_%A.out

module purge
module load 2023
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1

cd $HOME/AI_for_medical_imaging_course/Assignment\ 2
source /gpfs/work5/0/prjs1312/venv2/bin/activate

# # Define hyperparameter values
# learning_rates=(0.0001 0.001 0.01 0.1)
# batch_sizes=(32 64)
# epochs=(20)
# convolutional_channels=("16,32" "32,64" "64,128" "16,32,64" "32,64,128")
# dropout_rates=(0.0 0.25 0.5)
# optimizers=("adam")

# Define hyperparameter values
learning_rates=(0.0001)
batch_sizes=(32)
epochs=(60)
convolutional_channels=("32,64" "32,64,128" "16,32,64,128,256")
dropout_rates=(0.5 0.75)
optimizers=("adam")

# Run all hyperparameter combinations sequentially
for lr in "${learning_rates[@]}"; do
    for batch_size in "${batch_sizes[@]}"; do
        for epoch in "${epochs[@]}"; do
            for conv_channels in "${convolutional_channels[@]}"; do
                for dropout_rate in "${dropout_rates[@]}"; do
                    for optimizer in "${optimizers[@]}"; do
                        echo "Running: lr=$lr, batch_size=$batch_size, epochs=$epoch, conv_channels=$conv_channels, dropout_rate=$dropout_rate, optimizer=$optimizer"
                        srun python -u main_CNN.py --checkpoint_folder_save checkpoints/ \
                                                --optimizer_lr $lr \
                                                --batch_size $batch_size \
                                                --max_epochs $epoch \
                                                --conv_channels $conv_channels \
                                                --dropout_rate $dropout_rate \
                                                --optimizer_name $optimizer \
                                                --experiment_name ${optimizer_name}_lr${optimizer_lr}_bs${batch_size}_ch${conv_channels}_dr${dropout_rate}
                        sleep 5  # Small delay to avoid overwhelming the scheduler
                    done
                done
            done
        done
    done
done