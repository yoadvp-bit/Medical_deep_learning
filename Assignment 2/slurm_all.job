#!/bin/bash

learning_rates=(0.0001 0.001 0.01)
optimizer_set=("adam")
batch_set=(16 32 64)
convolutional_channels=("16,32" "32,64" "64,128")

for lr in "${learning_rates[@]}"; do
    for optimizer in "${optimizer_set[@]}"; do
        for batch_size in "${batch_set[@]}"; do
            for conv_channels in "${convolutional_channels[@]}"; do
                experiment_name="lr${lr}_opt${optimizer}_bs${batch_size}_ch${conv_channels//,/}" # Remove commas for filename
                slurm_script="slurm_jobs/${experiment_name}.slurm"
                
                mkdir -p slurm_jobs slurm_logs

                cat > "$slurm_script" <<EOL
#!/bin/bash
#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=$experiment_name
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=00:20:00
#SBATCH --output=slurm_logs/slurm_output_%A.out

module purge
module load 2023
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1

cd \$HOME/AI_for_medical_imaging_course/Assignment\ 2
source /gpfs/work5/0/prjs1312/venv/bin/activate

srun python -u main_CNN.py \
    --checkpoint_folder_save checkpoints/ \
    --optimizer_lr $lr \
    --batch_size $batch_size \
    --model_name custom_convnet \
    --optimizer_name $optimizer \
    --Conv_Channels $conv_channels \
    --dropout_rate 0 \
    --max_epochs 10 \
    --experiment_name $experiment_name
EOL
                
                sbatch "$slurm_script"
            done
        done
    done
done
