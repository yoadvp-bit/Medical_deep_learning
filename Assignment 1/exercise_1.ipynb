{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Deadline: first class in week 4 of the course: 25-2-2025 10:00 (if updated).\n",
    "Hand in this notebook with output. Make sure that it is able to run and produce all the figures and results you show. Also, use the text boxes to answer the questions and interpret your results, relating them to the course materials.\n",
    "\n",
    "\n",
    "Exercises made by Oliver Gurney-Champion. Please contact us via Canvas, or e-mail directly to:\n",
    "Oliver: o.j.gurney-champion@amsterdamumc.nl\n",
    "Matthan: m.w.a.caan@amsterdamumc.nl\n",
    "Dilara: d.tank@amsterdamumc.nl\n",
    "Daan: d.kuppens@amsterdamumc.nl\n",
    "\n",
    "These are a large set of challenging exercises, for which you will get 3 weeks to complete. I would strongly advise you to stick to the suggested schedule, which will ensure you have sufficient knowledge to answer the questions when completing them, and finalize all questions in time.\n",
    "\n",
    "Note that the networks will be lite and can run on your local computer/laptop in short time (minutes). There is no need as yet to run this on Surf, although we highly encourage you to make sure Surf works for you (for exercise sets 2 and 3).\n",
    "\n",
    "# Exercise 1: Program network in PyTorch. (60%)\n",
    "During the class, a brief introduction was given to quantitative imaging. In this exercise, you will program your first neural network that will help estimate quantitative MRI parameters from quantitative data. In particular, we will be looking at the intra-voxel incoherent motion (IVIM) model for diffusion-weighted MRI:\n",
    "\n",
    "S(b)=S_0×( (1-f)×e^-b×D^ +f×e^-b×D*^ )                                                                    [1]\n",
    "\n",
    "With S the measured signal, S0 the baseline signal at S(b=0), f the perfusion fraction, D the diffusion coefficient and D* the pseudo diffusion coefficient. For more information on what the model means exactly and how it is used clinically, I would suggest reading \"Introduction to IVIM MRI | Radiology Key\" (https://radiologykey.com/introduction-to-ivim-mri/). But for the purpose of this exercise, it is just a model.\n",
    "\n",
    "Normally, f, D and D* (named Dp in the code) are obtained by fitting S(b) using least-squares fitting. But these approaches are known to be prone to noise in the data and often produce poor estimates.\n",
    "\n",
    "Therefore, you will write a neural network that predicts f from a given S(b). There are great tools available that take care of training models, such as PyTorch, Karas and Tensorflow. However, for the purpose of this exercise, you will make use of PyTorch. Moreover, we will use weights-and-biasses to keep track of how training is going.\n",
    "\n",
    "# Wednesday 3-4-2024\n",
    "At https://github.com/oliverchampion/AI_for_medical_imaging_course you will find the Python assignment. To help visualize progress and to isolate certain snippets of code, we wrote this as a Jupyter Notebook (exercise1.ipynb). As you can see, we have already provided a data-generator, some plotting tools to plot the training progress. The notebook should run as is and train a neural network! For your first lecture, we suggest you (Wednesday)\n",
    "-\tInstall all prerequisites in your virtual enviroment (requierements.txt)\n",
    "-\tStart a WandB account @ https://wandb.ai/  you will need to log in when running the script\n",
    "-\tGo through the script to see whether you understand what happens.\n",
    "-\tTrain your first neural network .\n",
    "-\tVisualize the results on your WandB page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requiered packages\n",
    "imports the packages and sets the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper_functions as hf\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "\n",
    "# set random seed\n",
    "seed =42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "login to your free wandb account. Note you will need to set up your account on https://wandb.ai/authorize\n",
    "wandb allows you to keep track of your neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "%env WANDB_SILENT=True\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate and view the IVIM data\n",
    "This allows you to study what the data looks like in jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set b-values at which we \"measure\" (i.e. simulate signal)\n",
    "bvalues=[0, 10, 20, 30, 40, 50, 75, 100, 150, 250, 400, 600]\n",
    "\n",
    "## Set the random seeds for reproducibility\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "## Loading the (simulated) dataset\n",
    "data_sim, D, f, Dp = hf.sim_signal(SNR=(10,30),bvalues=bvalues,sims=30,seed=np.random.randint(1,10000))\n",
    "\n",
    "## plotting some curves and data for visualisation\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axs[i, j].plot(bvalues, data_sim[i+10*j,:], 'o')\n",
    "        datapred=hf.ivim(np.arange(0,np.max(bvalues)), D[i+10*j], f[i+10*j], Dp[i+10*j], 1)\n",
    "        axs[i, j].plot(np.arange(0,np.max(bvalues)), datapred)\n",
    "        axs[i, j].set_ylim(0, 1.2)\n",
    "        axs[i, j].set(xlabel='b-value (s/mm2)', ylabel='normalised signal')\n",
    "plt.legend(('noisy data', 'true curve'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and validation\n",
    "Here, we split our data into a training set, validation set and test set. Note that the current implementation only uses the training set and it is up to you (in your exercises) to also implement the validation and test run. At this point, we already split the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_dat(bvalues,batch_size = 16,SNR=(10,40),sims=1000,seed=69):   #removed the seed randomisation      np.random.randint(1,10000)):\n",
    "    with wandb.init(project=\"AI_for_medical_imaging\", job_type=\"visualize data\") as run:\n",
    "        data_sim = hf.sim_signal(SNR=SNR,bvalues=bvalues,sims=sims,seed=seed)\n",
    "        # Only for visualisation purposes: here we create our \"Artifact\" in wandb --> this allows viewing the data in your wandb account\n",
    "        for i in range(4):\n",
    "            #make b-value data pairs\n",
    "            example_data=[[x,y] for (x,y) in zip(bvalues,data_sim[0][i])]\n",
    "            # put it in a table\n",
    "            table = wandb.Table(data=example_data, columns=[\"b-values\", \"signal\"])\n",
    "            #tell wandb to plot the table\n",
    "            wandb.log({\"data_plot \" + str(i): wandb.plot.scatter(table, \"b-values\", \"signal\")})\n",
    "\n",
    "        # here we split the data into train (70%), test (15%) and validation (15%) sets\n",
    "        #split = int(np.floor(len(data_sim[0]) * 0.7))\n",
    "        train_set, test_set, val_set = torch.utils.data.random_split([[data_sim[0][i,:],data_sim[1][i],data_sim[2][i],data_sim[3][i]] for i in range(len(data_sim[3]))],[0.7,0.15,0.15])\n",
    "        #split = int(np.floor(len(rest) * 0.5))\n",
    "        #test_set, val_set = torch.utils.data.random_split([[rest[0][i,:],rest[1][i],rest[2][i],rest[3][i]] for i in range(len(rest[3]))],[split, len(rest[0]) - split])\n",
    "\n",
    "        # train loader loads the trianing data. We want to shuffle to make sure data order is modified each epoch and different data is selected each epoch.\n",
    "        trainloader = torch.utils.data.DataLoader(train_set,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       drop_last=True)\n",
    "        # validation data is loaded here. By not shuffling, we make sure the same data is loaded for validation every time. We can use substantially more data per batch as we are not training.\n",
    "        inferloader = torch.utils.data.DataLoader(val_set,\n",
    "                                       batch_size=min(batch_size,len(val_set)),\n",
    "                                       shuffle=False,\n",
    "                                       drop_last=False)\n",
    "            # validation data is loaded here. By not shuffling, we make sure the same data is loaded for validation every time. We can use substantially more data per batch as we are not training.\n",
    "        testloader = torch.utils.data.DataLoader(test_set,\n",
    "                                       batch_size=min(batch_size,len(test_set)),\n",
    "                                       shuffle=False,\n",
    "                                       drop_last=False)\n",
    "    return trainloader, inferloader, testloader\n",
    "sim_dat(bvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for stacking the layers and making the model\n",
    "def make_model(n_inputs=5,n_hidden=1, hidden_width=5, n_outputs=1):\n",
    "    #initialize the model object\n",
    "    model = nn.Sequential()\n",
    "    # add first hidden layer\n",
    "    model.add_module('first_layer', nn.Linear(n_inputs, hidden_width))\n",
    "    # add ReLu layer\n",
    "    model.add_module('first_ReLu', nn.ReLU())\n",
    "    # fill out the model with hidden layers.\n",
    "    for i in range(1, n_hidden):\n",
    "        # as we loop, we add hidden layers\n",
    "        model.add_module('layer_linear'+str(i), nn.Linear(hidden_width, hidden_width))\n",
    "        # we also add a ReLu layer\n",
    "        model.add_module('layer_ReLu'+str(i), nn.ReLU())\n",
    "    #and a final output layer\n",
    "    model.add_module('last_layer',nn.Linear(hidden_width, n_outputs))\n",
    "    # to ensure positive predictions, we end with a ReLu function before giving output\n",
    "    model.add_module('last',nn.Sigmoid())\n",
    "    model.apply(init_weights)\n",
    "    return model\n",
    "\n",
    "# function for initializing network weights for individual layers\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train your first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def train_network(name, epochs=200, learningrate=0.1, hidden_layers=2, hidden_width=5, seed=42, optimizer='SGD', bvalues=bvalues, batch_size=16, sims=1000, sim_seed=69):\n",
    "\n",
    "    trainloader, inferloader, testloader = sim_dat(bvalues, batch_size=batch_size, sims=sims, seed=sim_seed)\n",
    "\n",
    "    model = make_model(n_inputs=len(bvalues), n_hidden=hidden_layers, hidden_width=hidden_width, n_outputs=1)\n",
    "\n",
    "    # initialize model --> we did this above, but during the exercise, you might be re-running this part of the script several times with different settings. This way we make sure you re-initiate the training and don't continue in the last model\n",
    "    model.apply(init_weights)\n",
    "\n",
    "    # initialize wandb\n",
    "    wandb.init(\n",
    "            project=\"AI_for_medical_imaging\", job_type=\"training\", name=name)\n",
    "\n",
    "    # set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # probe available devices\n",
    "    if torch.cuda.is_available():  # GPU operation have separate seed\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Set default device. If GPU is available, the network will be trained on the GPU. Note that further down in the code, stuff will be sent \".to(device)\" to make sure it is available on the GPU.\n",
    "    device = torch.device('cpu')#'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # define the loss of the network (mean square error)\n",
    "    loss_module = nn.MSELoss(reduction='mean').to(device)\n",
    "\n",
    "    # the optimizer determines how strongly to update the network's weights based on the calculated loss.\n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learningrate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learningrate)\n",
    "    else:\n",
    "        raise NotImplementedError('this optimizer is not implemented yet...')\n",
    "\n",
    "\n",
    "    plot_data = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"SD_train\": [],\n",
    "        \"SD_val\": [],\n",
    "        \"sys_train\": [],\n",
    "        \"sys_val\": []\n",
    "    }\n",
    "\n",
    "    # loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # initiate losses to 0\n",
    "        train_loss_f = 0\n",
    "        val_loss_f = 0\n",
    "        # set model to training such that forward passes are remembered (requiered for backpropogating the loss)\n",
    "        model.train()\n",
    "        #loop over all training data0\n",
    "        SD_train = 0\n",
    "        sys_train = 0\n",
    "        for x in trainloader:\n",
    "            # reset the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            # get data (x[0]) and put the data on the GPU if available\n",
    "            batch = x[0].to(device)\n",
    "            # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            # put the data through the neural network\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            # calculate loss (compare predicted f to the ground trueth)\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            #add found loss to the train loss, to keep track of the loss this epoch\n",
    "            train_loss_f += loss_f.item()\n",
    "            # propogate the loss through the network (calculate d_weights/d_loss)\n",
    "            loss_f.backward()\n",
    "            # update all weights according to their derrivatives to the loss.\n",
    "            optimizer.step()\n",
    "            # calculate the standard deviation and systematic error on the trianing data\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(), f_ref.cpu().detach().numpy())\n",
    "            # add the errors to ultimately calculate their mean over the training data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "            SD_train += SD**2\n",
    "            sys_train += sys\n",
    "        # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "        SD_train = np.sqrt(SD_train/trainloader.__len__())\n",
    "        sys_train = sys_train/trainloader.__len__()\n",
    "        # after training, set model to evaluation mode\n",
    "        model.eval()\n",
    "        # initialize error_metrics\n",
    "        SD_val = 0\n",
    "        sys_val = 0\n",
    "        ######################your code here for validation loss#########################\n",
    "\n",
    "        for x in inferloader:\n",
    "            # get data (x[0]) and put the data on the GPU if available\n",
    "            batch = x[0].to(device)\n",
    "            # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "            f_ref = torch.flatten(x[2].to(device))\n",
    "            # put the data through the neural network\n",
    "            f_pred = torch.flatten(model.forward(batch))\n",
    "            # calculate loss (compare predicted f to the ground trueth)\n",
    "            loss_f = loss_module(f_pred, f_ref)\n",
    "            #add found loss to the validation loss, to keep track of the loss this epoch\n",
    "            val_loss_f += loss_f.item()\n",
    "            # calculate the standard deviation and systematic error on the validation data\n",
    "            SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(),f_ref.cpu().detach().numpy())\n",
    "            # add the errors to ultimately calculate their mean over the validation data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "            SD_val += SD**2\n",
    "            sys_val += sys\n",
    "\n",
    "        # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "        SD_val = np.sqrt(SD_val/inferloader.__len__())\n",
    "        sys_val = sys_val/inferloader.__len__()\n",
    "            \n",
    "        \n",
    "        #make b-value data pairs: Note these currently contain the f_ref and f_pred from the trianing data. You may want to swap to validation data once implemented\n",
    "        example_data=[[x,y] for (x,y) in zip(f_ref.cpu().detach().numpy(),f_pred.cpu().detach().numpy())]\n",
    "        # put it in a table\n",
    "        table = wandb.Table(data=example_data, columns=[\"f_ref\", \"f_pred\"])\n",
    "        #tell wandb to plot the table\n",
    "        # note that some parameters are being logged which you still need to define in the validation loop!\n",
    "        if epoch % 10 == 0:\n",
    "            wandb.log({\"loss/train\": train_loss_f/trainloader.__len__(),\"loss/val\": val_loss_f/inferloader.__len__(),\"error/random error\":SD_train,\"error/systematic error\":sys_train,\"data_plot epoch \" + str(epoch): wandb.plot.scatter(table, \"f_ref\", \"f_pred\", title=f'epoch{epoch}')})\n",
    "\n",
    "        plot_data[\"train_loss\"].append(train_loss_f/trainloader.__len__())\n",
    "        plot_data[\"val_loss\"].append(val_loss_f/inferloader.__len__())\n",
    "        plot_data[\"SD_train\"].append(SD_train)\n",
    "        plot_data[\"SD_val\"].append(SD_val)  \n",
    "        plot_data[\"sys_train\"].append(sys_train)\n",
    "        plot_data[\"sys_val\"].append(sys_val)\n",
    "\n",
    "        ## print output in terminal. Only useful for debugging when WandB does not work\n",
    "        #print('epoch = ' + str(epoch) + ' train loss =' + str(train_loss_f/trainloader.__len__()) +' val loss =' + str(val_loss_f/inferloader.__len__()) + 'the systematic error is ' + str(sys_val) + ' and the random error is ' + str(SD_val))\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    # initialize error_metrics\n",
    "    SD_test=0\n",
    "    sys_test=0\n",
    "    test_loss_f=0\n",
    "    ######################your code here for testing loss#########################\n",
    "\n",
    "    for x in testloader:\n",
    "        # get data (x[0]) and put the data on the GPU if available\n",
    "        batch=x[0].to(device)\n",
    "        # get the reference f (x[2]) --> note x[1] and x[3] are D and Dp respectively\n",
    "        f_ref = torch.flatten(x[2].to(device))\n",
    "        # put the data through the neural network\n",
    "        f_pred = torch.flatten(model.forward(batch))\n",
    "        # calculate loss (compare predicted f to the ground trueth)\n",
    "        loss_f = loss_module(f_pred, f_ref)\n",
    "        #add found loss to the validation loss, to keep track of the loss this epoch\n",
    "        test_loss_f += loss_f.item()\n",
    "        # calculate the standard deviation and systematic error on the validation data\n",
    "        SD, sys = hf.error_metrics(f_pred.cpu().detach().numpy(),f_ref.cpu().detach().numpy())\n",
    "        # add the errors to ultimately calculate their mean over the validation data. calculating mean SDs goes via the Root Mean Squares. So add SDs squared\n",
    "        SD_test += SD**2\n",
    "        sys_test += sys\n",
    "\n",
    "    # now divide by the total amount of training data to calculate the mean (sys error) and square of mean (SD).\n",
    "    SD_test = np.sqrt(SD_test/testloader.__len__())\n",
    "    sys_test = sys_test/testloader.__len__()\n",
    "    test_loss = test_loss_f/testloader.__len__()\n",
    "    \n",
    "    #return val_test SD_test\n",
    "    return plot_data, SD_test, sys_test, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots show how much the loss curves during training change with different seeds. This effect is very large and will overshadow many of the other effects discussed here. Additionally the validation loss is sometimes higher and sometimes lower than the testing loss, even in late stages of training. This is very uninuitive and could be caused by small datasets, where one dataset gives lower losses for the treaversed parameter space. This was tested by increasing the amount of simulations, which reduced the magnitude of the difference, but did not eleviate the artifact.\n",
    "\n",
    "The seed was fixed for all following plots for reproducability. Changes did still occur sometimes, which means there is likely still an unseeded random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    plot_data, SD_test, sys_test, test_loss = train_network('test', optimizer='adam', sim_seed=np.random.seed(500), epochs=50, sims=5000)\n",
    "\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axs[row, col].plot(plot_data[\"train_loss\"], label='train loss')\n",
    "    axs[row, col].plot(plot_data[\"val_loss\"], label='val loss')\n",
    "    axs[row, col].legend()\n",
    "    axs[row, col].grid()\n",
    "    axs[row, col].set_title(f'Seed {i}')\n",
    "    axs[row, col].set_ylim(0, 0.04)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    plot_data, SD_test, sys_test, test_loss = train_network('test', optimizer='SGD', sim_seed=np.random.seed(500), epochs=20)\n",
    "\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axs[row, col].plot(plot_data[\"train_loss\"], label='train loss')\n",
    "    axs[row, col].plot(plot_data[\"val_loss\"], label='val loss')\n",
    "    axs[row, col].legend()\n",
    "    axs[row, col].grid()\n",
    "    axs[row, col].set_title(f'Seed {i}')\n",
    "    axs[row, col].set_ylim(0, 0.04)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    plot_data, SD_test, sys_test, test_loss = train_network('test', optimizer='SGD', sim_seed=np.random.seed(500), epochs=50, sims=10000)\n",
    "\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axs[row, col].plot(plot_data[\"train_loss\"], label='train loss')\n",
    "    axs[row, col].plot(plot_data[\"val_loss\"], label='val loss')\n",
    "    axs[row, col].legend()\n",
    "    axs[row, col].grid()\n",
    "    axs[row, col].set_title(f'Seed {i}')\n",
    "    axs[row, col].set_ylim(0, 0.04)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First week (on schedule means finish by Friday) [if updated: 7-2-2025]\n",
    "For these exercises, you will want to produce new cells that generate the outputs. The notebook cells should run and produce the figures without input of the examiners.\n",
    "\n",
    "## 1A-C: train the neural network\n",
    "Adapt the script above for your exercises A-C such that it produces the desired results and plots. Describe the results/intepertation in this text baloon.\n",
    "\n",
    "A. The current network implementation only looks at training data. This means that the network’s performance is over-estimated. Please use the validation set to monitor performance during training (note that we have already put the model on evaluation mode in line 59). At what point is the network fully trained? Explain how you know this. Show the effect from overfitting and underfitting.\n",
    "\n",
    "The model is fully trained only at the very end of the epochs loop, so once the function has finished running. This is because the model changes the weights (optimiser.step()) for every iteration in the epochs loop (only in the training loop).\n",
    "\n",
    "At first the model underfits, here the training loss is higher than the validation loss and the slope of the validation loss curve is negative. Overfitting does not occur in this example. The validation curve stays flat for after 175 epochs and does not start to rise again (yet). (This could change however if the model is retrained due to the some random parameters)\n",
    "\n",
    "B. Similarly, use the test dataset to test for final performance. Explain why this is needed.\n",
    "\n",
    "Once the model is fully trained we need to test the performance on a dataset that is new to the model. Otherwise the fact that the model was trained on the data would bias the performance. And if the validation set was used to determine the point where to stop training, this would also have an influence on the model, which is why a completely new dataset is chosen.\n",
    "\n",
    "C. Currently, standard gradient descent optimizer is being used to train the network, with a learning rate of 0.01. Investigate the performance of the network for different optimizer (i.e. adam loss was discussed in the lecture) and explain what you see. What does the Adam optimizer do differently from the SGD optimizer that would make it perform better/differently?\n",
    "\n",
    "The SGD optimizer uses just the gradient and a constant learning rate to find minima in the loss function.\n",
    "The adam optimizer uses both momentum (past gradients influence the step size (moving average)) and a decay of the moments (only a certain amount of past gradients to an extend defined by an exponential decay) in addition to the gradient and a learning rate to converge to a minimum faster than SGD.\n",
    "\n",
    "The adam optimizer tends to find a minimum in the loss function much quicker than the SGD optimiser. \n",
    "The loss curve during training of the adam optimiser shows much higher variance than the one of the SGD optimiser. This is likely caused by the momentum in the adam optimiser, which means even when in a minimum, where the slope in the loss function vanishes, the step size is not 0. A step size unequal to 0 would mean that the optimizer takes a step out of the minimum. The fact that this carries on for many epochs likely means that the decay is not tuned properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_ADAM, SD_test_ADAM, sys_test_ADAM, test_loss_ADAM = train_network('test_ADAM', optimizer='adam', sim_seed=69)\n",
    "\n",
    "fig,axs = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "fig.suptitle('ADAM optimizer')\n",
    "\n",
    "axs[0].semilogy(plot_data_ADAM['train_loss'], label='train loss')\n",
    "axs[0].semilogy(plot_data_ADAM['val_loss'], label='validation loss')\n",
    "axs[0].axhline(y=test_loss_ADAM, color='r', linestyle='--', label='test loss')\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].set_ylabel('loss')\n",
    "\n",
    "\n",
    "axs[1].plot(plot_data_ADAM['sys_train'], label='train sys error')\n",
    "axs[1].plot(plot_data_ADAM['sys_val'], label='validation sys error')\n",
    "axs[1].axhline(y=sys_test_ADAM, color='r', linestyle='--', label='test sys error')\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].set_ylabel('systematic error')\n",
    "\n",
    "\n",
    "axs[2].plot(plot_data_ADAM['SD_train'], label='train SD')\n",
    "axs[2].plot(plot_data_ADAM['SD_val'], label='validation SD')\n",
    "axs[2].axhline(y=SD_test_ADAM, color='r', linestyle='--', label='test SD')\n",
    "axs[2].legend()\n",
    "axs[2].set_xlabel('epoch')\n",
    "axs[2].set_ylabel('standard deviation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_SGD, SD_test_SGD, sys_test_SGD, test_loss_SGD = train_network('test_SGD', optimizer='SGD')\n",
    "\n",
    "fig,axs = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "fig.suptitle('SGD optimizer')\n",
    "\n",
    "axs[0].semilogy(plot_data_SGD['train_loss'], label='train loss')\n",
    "axs[0].semilogy(plot_data_SGD['val_loss'], label='validation loss')\n",
    "axs[0].axhline(y=test_loss_SGD, color='r', linestyle='--', label='test loss')\n",
    "axs[0].legend()\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].set_ylabel('loss')\n",
    "\n",
    "\n",
    "axs[1].plot(plot_data_SGD['sys_train'])\n",
    "axs[1].plot(plot_data_SGD['sys_val'])\n",
    "axs[1].axhline(y=sys_test_SGD, color='r', linestyle='--')\n",
    "axs[1].legend(['train sys error', 'validation sys error', 'test sys error'])\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].set_ylabel('systematic error')\n",
    "\n",
    "\n",
    "axs[2].plot(plot_data_SGD['SD_train'], label='train SD')\n",
    "axs[2].plot(plot_data_SGD['SD_val'], label='validation SD')\n",
    "axs[2].axhline(y=SD_test_SGD, color='r', linestyle='--', label='test SD')\n",
    "axs[2].legend()\n",
    "axs[2].set_xlabel('epoch')\n",
    "axs[2].set_ylabel('standard deviation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "fig.suptitle('Comparison of SGD and ADAM optimizers')\n",
    "\n",
    "axs[0].semilogy(plot_data_SGD['val_loss'], color='b')\n",
    "axs[0].semilogy(plot_data_ADAM['val_loss'], color='r')\n",
    "axs[0].axhline(y=test_loss_SGD, color='b', linestyle='--')\n",
    "axs[0].axhline(y=test_loss_ADAM, color='r', linestyle='--')\n",
    "axs[0].legend(['SGD validation loss', 'ADAM validation loss', 'SGD test loss', 'ADAM test loss'])\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].set_ylabel('loss')\n",
    "\n",
    "\n",
    "axs[1].plot(plot_data_SGD['sys_val'], color='b')\n",
    "axs[1].plot(plot_data_ADAM['sys_val'], color='r')\n",
    "axs[1].axhline(y=sys_test_SGD, color='b', linestyle='--')\n",
    "axs[1].axhline(y=sys_test_ADAM, color='r', linestyle='--')\n",
    "axs[1].legend(['SGD validation sys error', 'ADAM validation sys error', 'SGD test sys error','ADAM test sys error'])\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].set_ylabel('systematic error')\n",
    "\n",
    "\n",
    "axs[2].semilogy(plot_data_SGD['SD_val'], color='b')\n",
    "axs[2].semilogy(plot_data_ADAM['SD_val'], color='r')\n",
    "axs[2].axhline(y=SD_test_SGD, color='b', linestyle='--')\n",
    "axs[2].axhline(y=SD_test_ADAM, color='r', linestyle='--')\n",
    "axs[2].legend(['SGD validation SD', 'ADAM validation SD', 'SGD test SD', 'ADAM test SD'])\n",
    "axs[2].set_xlabel('epoch')\n",
    "axs[2].set_ylabel('standard deviation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D.\tReturn back to SGD. Test how the performance depends on the learning rate. This can be done by plotting the systematic (sys_test) and random (SD_test) errors as function of learning rate (10<LR<0.0000001; steps in order of magnitude; e.g. 10, 1, 0.1, ….).\n",
    "##### Plot the performance (sys_val and SD_val) as function of the learning rate and add this to your report. Explain what you see (hint: take a look at the loss curves).\n",
    "easiest is to save the final performance and plot it in the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network using the SGD optimizer for different learning rates\n",
    "\n",
    "learning_rate = np.logspace(-7, 1, 8)\n",
    "\n",
    "sys_val_list = []\n",
    "sys_test_list = []\n",
    "SD_val_list = []\n",
    "SD_test_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for rates in learning_rate:\n",
    "    plot_data, SD_test, sys_test, test_loss = train_network('test_SGD', optimizer='SGD', learningrate=rates)\n",
    "    \n",
    "    sys_val_list.append(plot_data['sys_val'][-1])\n",
    "    sys_test_list.append(sys_test)\n",
    "    SD_val_list.append(plot_data['SD_val'][-1])\n",
    "    SD_test_list.append(SD_test)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "fig,axs = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "axs[0].plot(learning_rate, sys_val_list)\n",
    "axs[0].plot(learning_rate, sys_test_list)\n",
    "axs[0].legend(['validation sys error', 'test sys error'])\n",
    "axs[0].set_xlabel('learning rate')\n",
    "axs[0].set_ylabel('systematic error')\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].plot(learning_rate, SD_val_list)\n",
    "axs[1].plot(learning_rate, SD_test_list)\n",
    "axs[1].legend(['validation SD', 'test SD'])\n",
    "axs[1].set_xlabel('learning rate')\n",
    "axs[1].set_ylabel('standard deviation')\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extra plot for test loss\n",
    "plt.plot(learning_rate, test_loss_list)\n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('test loss')\n",
    "plt.xscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.\tPlot the performance (sys_val and SD_val) as function of the width (number of neurons per layer: 5, 10, 20, 50, 100) and depth (number of hidden layers: 1, 2, ..., 8) of the network and add these to the report. Discuss how width and depth may influence the network; if it has this behaviour in your data, highlight it; if not, explain why it may not occur in your dataset.\n",
    "\n",
    "Hint: currently, the width of the network copies the width of the data, so you need to uncouple the input width from the network width by adapting the \"make model\" code.\n",
    "Tip: you only need to plot different widths for 1 depth (e.g. 2) and different depths for 1 width (e.g. 10).\n",
    "Tip: possibly some effects get clearer when more training data is simulated (\"sims\" in data_sim). But also note that having too much training data may hide some of the effects from other exercises, so don't forget to revert it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plots that are shown are the losses during training for the different network depths. These all have rouhgly the same trajectory, with some outliers, where the training loss seems to stay constant right away likely due to getting stuck in a local minimum.\n",
    "\n",
    "The next set of plots shows the losses, systemic error and standard deviation for the testing dataset and the last epoch run of the validation dataset as a function of depth and width. For the depth plots the width was set to 5. For the width plots the depth was set to 2. \n",
    "\n",
    "For the depth, the magnitude of the systematic error increases with depth slightly, while the standard deviation stays constant apart from Some outlier peaks. This is likely caused by the same artifact that can be seen at the correseponding depths in the first set of plots. For all plots as a function of depth the validation and test curves are very similar. \n",
    "\n",
    "For the test dataset curve the width increases the magnitude of the systematic error at first and then decreases again. The validation curve has a similar trajectory but shifted to higher values. The standard deviation decreases for both datasets at first but then increases again slightly for the validation curve, while the test curve keeps falling slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network using the SGD optimizer for different depths and layer widths\n",
    "\n",
    "depth = np.linspace(1, 8, 8, dtype=int)\n",
    "\n",
    "layer_width = [5, 10, 20, 50, 100]\n",
    "\n",
    "sys_val_list_depth = []\n",
    "sys_test_list_depth = []\n",
    "SD_val_list_depth = []\n",
    "SD_test_list_depth = []\n",
    "test_loss_list_depth = []\n",
    "\n",
    "sys_val_list_width = []\n",
    "sys_test_list_width = []\n",
    "SD_val_list_width = []\n",
    "SD_test_list_width = []\n",
    "test_loss_list_width = []\n",
    "\n",
    "fig_loss, axs_loss = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# leaving the width as 5 and changing the depth. Leaving width as 5 to be able to compare to the previous results\n",
    "for i, layers in enumerate(depth):\n",
    "    plot_data, SD_test, sys_test, test_loss = train_network('test_SGD', optimizer='SGD', hidden_layers=layers, sims = 5000, sim_seed=69)\n",
    "\n",
    "    axs_loss[i // 4, i % 4].set_title(f'Depth {layers}')\n",
    "    axs_loss[i // 4, i % 4].semilogy(plot_data['val_loss'], label='validation loss')\n",
    "    axs_loss[i // 4, i % 4].semilogy(plot_data['train_loss'], label='train loss')\n",
    "    axs_loss[i // 4, i % 4].legend()\n",
    "    axs_loss[i // 4, i % 4].set_xlabel('epoch')\n",
    "    axs_loss[i // 4, i % 4].set_ylabel('loss')\n",
    "    \n",
    "    sys_val_list_depth.append(plot_data['sys_val'][-1])\n",
    "    sys_test_list_depth.append(sys_test)\n",
    "    SD_val_list_depth.append(plot_data['SD_val'][-1])\n",
    "    SD_test_list_depth.append(SD_test)\n",
    "    test_loss_list_depth.append(test_loss)\n",
    "\n",
    "fig_loss.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "# leaving the depth as 2 and changing the width. Leaving depth as 2 to be able to compare to the previous results\n",
    "for width in layer_width:\n",
    "    plot_data, SD_test, sys_test, test_loss = train_network('test_SGD', optimizer='SGD', hidden_layers=2, hidden_width=width, sims= 10000, sim_seed=69)\n",
    "    \n",
    "    sys_val_list_width.append(plot_data['sys_val'][-1])\n",
    "    sys_test_list_width.append(sys_test)\n",
    "    SD_val_list_width.append(plot_data['SD_val'][-1])\n",
    "    SD_test_list_width.append(SD_test)\n",
    "    test_loss_list_width.append(test_loss)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "fig.suptitle('Effect of Depth and Width on Network Performance')\n",
    "\n",
    "# Plot for depth\n",
    "axs[0, 0].plot(depth, sys_val_list_depth)\n",
    "axs[0, 0].plot(depth, sys_test_list_depth)\n",
    "axs[0, 0].legend(['validation sys error', 'test sys error'])\n",
    "axs[0, 0].set_xlabel('depth')\n",
    "axs[0, 0].set_ylabel('systematic error')\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "axs[0, 1].plot(depth, SD_val_list_depth)\n",
    "axs[0, 1].plot(depth, SD_test_list_depth)\n",
    "axs[0, 1].legend(['validation SD', 'test SD'])\n",
    "axs[0, 1].set_xlabel('depth')\n",
    "axs[0, 1].set_ylabel('standard deviation')\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "axs[0, 2].plot(depth, test_loss_list_depth)\n",
    "axs[0, 2].set_xlabel('depth')\n",
    "axs[0, 2].set_ylabel('test loss')\n",
    "axs[0, 2].grid(True)\n",
    "\n",
    "# Plot for width\n",
    "axs[1, 0].plot(layer_width, sys_val_list_width)\n",
    "axs[1, 0].plot(layer_width, sys_test_list_width)\n",
    "axs[1, 0].legend(['validation sys error', 'test sys error'])\n",
    "axs[1, 0].set_xlabel('layer width')\n",
    "axs[1, 0].set_ylabel('systematic error')\n",
    "axs[1, 0].grid(True)\n",
    "\n",
    "axs[1, 1].plot(layer_width, SD_val_list_width)\n",
    "axs[1, 1].plot(layer_width, SD_test_list_width)\n",
    "axs[1, 1].legend(['validation SD', 'test SD'])\n",
    "axs[1, 1].set_xlabel('layer width')\n",
    "axs[1, 1].set_ylabel('standard deviation')\n",
    "axs[1, 1].grid(True)\n",
    "\n",
    "axs[1, 2].plot(layer_width, test_loss_list_width)\n",
    "axs[1, 2].set_xlabel('layer width')\n",
    "axs[1, 2].set_ylabel('test loss')\n",
    "axs[1, 2].grid(True)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plots that are shown are the losses during training for the different network depths. These all have rouhgly the same trajectory, with some outliers, where the training loss seems to stay constant right away likely due to getting stuck in a local minimum.\n",
    "\n",
    "The next set of plots shows the losses, systemic error and standard deviation for the testing dataset and the last epoch run of the validation dataset as a function of depth and width. For the depth plots the width was set to 5. For the width plots the depth was set to 2. \n",
    "\n",
    "For the depth, the magnitude of the systematic error increases with depth slightly if the outliers are ignored, while the standard deviation stays constant apart from the outlier peaks. The outliers are likely caused by the same artifact that can be seen at the correseponding depths in the first set of plots. For all plots as a function of depth the validation and test curves are very similar. \n",
    "\n",
    "For the test dataset curve, the width increases the magnitude of the systematic error at first and then decreases again after a width of 20. The validation curve has a similar trajectory but is shifted to higher values. The standard deviation decreases for both datasets at first but then increases again slightly for the validation curve, while the test curve keeps falling slightly.\n",
    "\n",
    "The test loss stays roughly constant apart from the outliers for the depth plot while it drops slightly for the width plot.\n",
    "\n",
    "\n",
    "\n",
    "The number of hidden layers (depth) does not seem to have a large impact on the performance of the neural network. The width of the hidden layers improved performance very slighly, reducing the systematic error slightly above a width of 20 layers. This could mean that higher widths are better able to reproduce the ground truth, although the changes were not large nor consitent enough to confirm this.\n",
    "\n",
    "In conclusion, the changes in performance due to changing the network size were marginal and not consistent, further testing is necessary to find a more meaningful conclusion.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F.\tTry different batch sizes (1, 4, 16, 64, 128, 516).Explain the behavior of the network you see.What is the effect of having smaller batches? And larger batches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsizes = [1, 4, 16, 64, 128, 512]  # Corrected 516 to 512\n",
    "cmap = plt.cm.get_cmap('jet', len(batchsizes))\n",
    "\n",
    "test_loss_list = []\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5)) \n",
    "\n",
    "for i, size in enumerate(batchsizes):\n",
    "    plot_data, SD_test, sys_test, test_loss = train_network('test_SGD', optimizer='SGD', batch_size=size)\n",
    "\n",
    "    axs[0].semilogy(plot_data['val_loss'], color=cmap(i), label=f'val Loss size {size}')\n",
    "    test_loss_list.append(test_loss)\n",
    "\n",
    "# Second plot for test loss\n",
    "axs[1].semilogx(batchsizes, test_loss_list, marker='o', label='test loss')\n",
    "\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[1].set_xlabel('Batch size')\n",
    "axs[1].set_ylabel('Test loss')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G.Chose 3 hidden layers, width of 40,  learning rate of 0.1 and batch size of 2. Now train the network for 3000 epochs. At what point in the network fully trained? How do you see this? Does any overfitting occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.Chose 3 hidden layers, width of 40,  learning rate of 0.1 and batch size of 2. Now train the network for 3000 epochs. At what point in the network fully trained? How do you see this? Does any overfitting occur?\n",
    "\n",
    "plot_data_G, SD_test_G, sys_test_G, test_loss_G = train_network('test_SGD', optimizer='SGD', epochs=3000, hidden_layers=3, hidden_width=40, learningrate=0.1, batch_size=2)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.semilogy(plot_data_G['train_loss'], label='train loss')\n",
    "plt.semilogy(plot_data_G['val_loss'], label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Simple Moving Average (SMA)\n",
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "# Apply moving average with a window size of 50 \n",
    "window_size = 50\n",
    "smoothed_train_loss = moving_average(plot_data_G['train_loss'], window_size)\n",
    "smoothed_val_loss = moving_average(plot_data_G['val_loss'], window_size)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.semilogy(smoothed_train_loss, label='Train Loss (Smoothed)')\n",
    "plt.semilogy(smoothed_val_loss, label='Validation Loss (Smoothed)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second week (on schedule means finish by Wednesday) [if updated: 12-2-2025]\n",
    "H.\tCurrently, the model uses a Relu activation function. Test the effect of different activation funtions on the network performance. Show how well does a sigmoid or ELU work (i.e. what is the effect on performance)?\n",
    "\n",
    "Note, you can either:\n",
    "- adapt the scripts above to program this \"neatly\" as input parameter.\n",
    "- redefine new \"programs\" below that have the new properties you want.\n",
    "\n",
    "Note that in the case of option 1, your programs need to stay backwards compatible, as examiners will need to be able to rerun your code and reproduce your results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we simualted a small amount of data, as it is easier to show overfitting etc. Note that you may want to simulate somewhat more data for this and the following exercises. This can be achieved by setting sims=100000 for the following exercises\n",
    "\n",
    "I.\tLet the network also predict D and Dp (note x[1] and x[3] are D and Dp respectively). Show the loss curve of D and Dp and explain how you can see that they have been implemented properly/the model is learning them.\n",
    "o\tThe network will need more than 1 output --> tip, use loss_D.backward(retain_graph=True) for the first two losses to remember losses and propogate all 3 losses backward in turn\n",
    "o\tAlternatively, you could train 3 networks simultaniously\n",
    "Note that 0<f<1 on avergae is orders of magnitude larger than D and Dp. To ensure all three losses equally affect the network weights you may want to enlarge the loss of D and Dp by multiplying them with some value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J.\tUse the sigmoid in the final layer to constrain 0.5e-3 <D< 3.5e-3; 0<f<1; 5e-3<D*<130e-3. Explain how you did this.\n",
    "Note: D, f and D* are in very different parameter value ranges, and hence their RMS is too. A network will focus on the largest loss. You may want to scale the RMS to similar ranges for the network to consider all 3 parameters during optmizing.\n",
    "Also note: You may want to play with hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For scoring 7.5+\n",
    "So far, you have been working with simulated data (taken care of by Data_loader.py). For such data, we know the ground truth values. However, in vivo, we have no way of knowing the ground truth. How will our network perform? Note that for this exercise you may need ot play with hyperparameters and design choices to train.\n",
    "\n",
    "K.\tUse the network, as trained in (J) and apply it to real-world data which is provided by running “dataval, valid_id, bvalues = hf.load_real_data(eval=True)”.\n",
    "- You will need to export you trained network in the return of the \"train_network\" function\n",
    "- you will need to apply it to the \"dataval\" from hf.load_real_data(eval=True)\n",
    "- you will then want to put the outputs through \"hf.plot_example(np.squeeze(D_out), valid_id,0.003)\", \"hf.plot_example(np.squeeze(f_out), valid_id,0.7)\" and \"hf.plot_example(np.squeeze(Dp_out), valid_id,0.1)\", with the predicted D, f and Dp being D_out, f_out and Dp_out.\n",
    "\n",
    "Note that alongside your plot (the first), also a conventional least squares fit is provided as a reference. Show the resulting parameter maps. How does your approach compare? Why do you think your particular approach would look better/worse?\n",
    "\n",
    "L.\tIdeally, you would train your network on real-world data. However, in this particular case, it is hard to get gold standard references. Luckily, we can use our understanding of physics, and of how stuff “should behave” to work our way around this. You will redesign your network loss, such that it can train on data without any gold standard references! Instead of placing the L2 loss on f_pred v.s. f_ref. Currently, the network is learning to minimize the difference between predicted fpred and the ground truth referene ftrue. In vivo, we may not have these references. To overcome this, we will now introduce a physics-informed loss. Use the IVIM equation [1] to propogate the predictions (D, f and Dp) into the signal space (S). Then, take e.g. the mean-square-error between the predicted signal and the input signal. Note that you will need to use torch functions (instead of numpy functions) to ensure you can backpropogate the loss through the equation into the network. You can train this network on the simulated data from earlier exercises. But it should also be able to train it on the in vivo data from \"datatrain, bvalues = hf.load_real_data(eval=False)\". This ensures that the network is use to looking at \"real\" data. Optimize the network’s training using the real data provided (“test_in_vivo.py”; datatrain). Evaluate the network on the same data as in 1 (data, valid_id, bvalues = dl.load_real_data(eval=True)). How does it perform?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain, bvalues = hf.load_real_data(eval=False)\n",
    "dataval, valid_id, bvalues = hf.load_real_data(eval=True)\n",
    "print('training data is ' + str(len(datatrain)) + ' long')\n",
    "\n",
    "''''your code here'''\n",
    "### use datatrain to train your network.\n",
    "## then test your network using dataval.\n",
    "''''if you manage to make predictions of D, f and Dp, the following code will allow you to plot them:'''\n",
    "\n",
    "hf.plot_example(np.squeeze(D_out), valid_id,0.003)\n",
    "hf.plot_example(np.squeeze(f_out), valid_id,0.7)\n",
    "hf.plot_example(np.squeeze(Dp_out), valid_id,0.1)\n",
    "hf.plot_ref()\n",
    "\n",
    "### you can compare supervised and self-supervised fits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
